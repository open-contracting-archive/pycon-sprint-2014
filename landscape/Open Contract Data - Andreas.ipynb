{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Problem\n",
      "\n",
      "We have a list of header names (e.g. \"REFERENCENUMBER\", \"document_id\", \"buyer\", ...). \n",
      "We want to find out which of these header names belong to a given entity (e.g. \"buyer\" or \"award\").\n",
      "In general, an entity is composed of multiple header names and multiple entities can be contained in a single\n",
      "set of header names.\n",
      "\n",
      "The classification algorithm should accomplish two things:\n",
      "\n",
      "* For a list of header names, return the entity types that are contained within (multilabel classification)\n",
      "* For a given header name, return the entity types to which it could belong\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from words import split_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import samples\n",
      "reload(samples)\n",
      "import samples\n",
      "#This returns a dict containing all header name combinations for a given entity type.\n",
      "samples = samples.load_samples_by_entity([\"Keywords\", \"UK\", \"Georgia\", \"Canada\", \"Mexico\", \"EU\"], cache=True)\n",
      "headers = samples.keys()\n",
      "print \"Entity types:\",\", \".join(samples.keys())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Entity types: notice, good, solicitation, authority, supplier, contract, buyer, ?\n"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Example: header name combinations for 'buyer' entity\n",
      "print dict(samples)['buyer']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['purchaser', 'procurer', 'requirements', 'code, sponsor'], ['ORG_NAME', 'ORG_CONTACTEMAIL', 'REGION'], ['procurring_entity_id', 'procurer_name', 'procurer_code'], ['end_user_entity', 'customer_info'], ['GOVERNMENT', 'ACRONYMS', 'UNIT', 'CompraNet Unit Identifier', 'CompraNet Unit name', 'Responsibility', 'Unit Branch'], ['document_country']]\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the classification, we first use a DictVectorizer to generate a sparse feature matrix from the header name occurences. Then, we use a linear support vector classifier to classify the headers.\n",
      "\n",
      "* http://scikit-learn.org/0.11/modules/generated/sklearn.feature_extraction.DictVectorizer.html\n",
      "* http://scikit-learn.org/stable/modules/feature_extraction.html\n",
      "* http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.feature_extraction import text,DictVectorizer\n",
      "\n",
      "pipe = Pipeline([ \n",
      "        ('hv', DictVectorizer()), \n",
      "        ('svm', LinearSVC()),\n",
      "    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#We generate the input training data set.\n",
      "#For each entity type, we generate a dict containing header name occurences for a given entity type and sample.\n",
      "from collections import defaultdict\n",
      "counts = []\n",
      "entities = []\n",
      "for entity,headers_list in samples.items():\n",
      "    for headers in headers_list:\n",
      "        counts.append(dict([(header,1) for header in headers]))\n",
      "        entities.append(entity)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#We fit the counts to the entities\n",
      "pipe.fit(counts,entities)\n",
      "\n",
      "#We predict the type of a given header name\n",
      "pipe.predict([{'NOTICETYPE' : 1}]),entities[30]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 269,
       "text": [
        "(array(['notice'], \n",
        "      dtype='|S12'), 'contract')"
       ]
      }
     ],
     "prompt_number": 269
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "\n",
      "rs = cross_validation.ShuffleSplit(len(counts), n_iter=2, train_size=0.75, test_size=.25)\n",
      "\n",
      "for train_index, test_index in rs:\n",
      "    print 'train', train_index, '\\ntest', test_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train [ 7 18 23  1 16 15 25 12 11  0 39  9 35 31  6 38  2 32 22 20 10 41 24 28 17\n",
        " 19  5 30 33 26 13] \n",
        "test [36  3  4 34 40 37  8 29 14 27 21]\n",
        "train [ 7 18 31 30  9 20  5 28  0  4 22 40  1 10 19 23 11 12 41 24 29 33 38  6 17\n",
        " 16  2 32 27 26 36] \n",
        "test [15 14 25 34 13 39 21  8  3 35 37]\n"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Performance of this model is poor because sample size is very small.\n",
      "for train_index, test_index in rs:\n",
      "    pipe.fit([counts[i] for i in train_index], [entities[i] for i in train_index])\n",
      "    print pipe.score([counts[i] for i in test_index],[entities[i] for i in test_index])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 275
    }
   ],
   "metadata": {}
  }
 ]
}