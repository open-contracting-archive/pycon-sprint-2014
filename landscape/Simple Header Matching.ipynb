{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from words import split_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import samples\n",
      "reload(samples)\n",
      "data = samples.load_samples([\"Keywords\", \"UK\", \"Georgia\", \"Canada\"], cache=True)\n",
      "headers = data.keys()\n",
      "print headers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['notice', 'good', 'solicitation', 'contract', 'supplier', 'authority', 'buyer', '?']\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def analyzer(list_of_headers):\n",
      "    \"\"\"\n",
      "    Takes a list of headers and returns a set of synonym names in the headers.\n",
      "    \"\"\"\n",
      "    result = set()\n",
      "    for header in list_of_headers:\n",
      "        for part in split_words(header):\n",
      "            if isinstance(part, basestring):\n",
      "                result.add( part )\n",
      "            else:\n",
      "                result.update( tuple(part) )\n",
      "    return set(result)\n",
      "\n",
      "def likeness(a, b):\n",
      "    \"\"\"\n",
      "    Returns how alike words found in the list a and words found in the list b are.\n",
      "    \"\"\"\n",
      "    a_set = analyzer(a)\n",
      "    b_set = analyzer(b)\n",
      "    union = a_set.union(b_set)\n",
      "    intersection = a_set.intersection(b_set)\n",
      "    return float(len(intersection)) / len(union)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#{'entity': '?', 'headers':[], 'top5rows': '', 'filename':}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "I. Define Raw Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame([[k,each] for k,v in data.items() for each in v], columns=['outcome', 'header'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "II. Define Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['length'] = df['header'].apply(len)\n",
      "df['word_count'] = df['header'].apply(lambda x: len(list(split_words(x))))\n",
      "df['header_in_outcome'] = df['header'].str.lower().isin(df['outcome'].str.lower())\n",
      "df['outcome_in_header'] = df['outcome'].str.lower().isin(df['header'].str.lower())\n",
      "\n",
      "# df['is_date'] = df['header'] \n",
      "# df['is_int'] = 1,0\n",
      "\n",
      "def set_affinity_fn(header_name):\n",
      "    header_set = analyzer(data[header_name])\n",
      "    def fn(x):\n",
      "        return likeness(header_set, analyzer(x))\n",
      "    return fn\n",
      "\n",
      "term_features = []\n",
      "for header in headers:\n",
      "    df['term_%s' % header] = df['header'].apply( set_affinity_fn(header) )\n",
      "    term_features.append( 'term_%s' % header )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "III. Combine Features into Feature Matrix & Define Outcome"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn import preprocessing\n",
      "#lb = preprocessing.LabelBinarizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df[['length','word_count', 'header_in_outcome', 'outcome_in_header']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = df.outcome"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "IV. Create Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import LinearSVC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "V. Split Data into Test and Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rs = cross_validation.ShuffleSplit(len(X), n_iter=5, train_size=0.5, test_size=.25, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for train_index, test_index in rs:\n",
      "    print 'train', train_index, '\\ntest', test_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train [107  40  22 113 144 132 148 108  27 121  86  61 106  18  96  30 145  71\n",
        " 110   2  59  97  85  43  10  74 157  98 123 147 130 135  50 112  83  64\n",
        " 109 111  69  49  48  13 120  23 122  20  15  78  52  76   3 162  95   6\n",
        "  68  75  84 161  12 126 139  14   0  91 152  46  11 102  35  57  41 159\n",
        "  65   1 133 151  42 105   4 141  17] \n",
        "test [160 149  73   7 100  54 125  44  26  90 136  94 131  80  62 119  37 154\n",
        " 101 142  51 138  33  45 146   8 150  89  92 124  63  55  93  24  56 118\n",
        "  19  66 134  16  60]\n",
        "train [ 52  60  56 153 107 136  78 109  21 115  74 144  49  19 137  28  72   7\n",
        "   6 105  92  22 135  65 134  66 100  12 114 131  17 150  96 124  30  82\n",
        " 123  25  48  94 149 122  81   1 103   8  62  80 133  69  98  75   0  36\n",
        "   5  33  88  99  34 143  97  85  61 158 154  45 130  10 120 156 116 108\n",
        "  50  90 127 139  23 151  73   9  39] \n",
        "test [ 77  47  95  84  38  76  15  91  64  57 157  89  68  59 110 112  26   4\n",
        "  63  37 126  42 155  55  58 119  54 160 161  14 113 128 106  86 132 141\n",
        " 102 101  16  87 146]\n",
        "train [158  50 147 122  45  32 157 111  28  96  40 150 119 138   5  69 160  64\n",
        " 112  39 120 115   1 137  12 133  76 146  35 118  91 132  93  31  63  43\n",
        "  10  47  68 107  85  65  42   3 103 123  36  83 162 153   9   7  86 149\n",
        " 143  33  29  27 113  57 101  97  20  25  54  30 145  49 108 100 159  24\n",
        "  23 109 114  56  16  60  66 127  84] \n",
        "test [142 129  75 128 130 151  82 140  17 125   2  15  77 104  90  88  46 102\n",
        "  14  78  72  62 116 156 141 135  11 155  67  61  19  37 131 110  98  21\n",
        "  95  41  73 126 161]\n",
        "train [116 140  36  40  49  55  24  30  52  17 153 113  18  14 142  74 107 161\n",
        " 120 152  99  42 162 141 137  76  62  85 115 124   5   1  97 127  16  45\n",
        "  95  25   8  35  81 122  21  77  54 150 103 111 125  28 135  20  70 102\n",
        "  83  43  37  60   3  79  34  88  69  64 131  56  27 157  10  72 130  80\n",
        " 154  96  12  33 129 121 143  50 159] \n",
        "test [ 13  67 146  89 123  75  58 110 134 160  84 112 136  48 126 155  86 144\n",
        " 147 117   0 149   9 139  11  44  38 106 108  23  19   2  32 151  29  63\n",
        "  39   7  68  41 133]\n",
        "train [ 55 129  77  46  82  36 148 118  22 131  69 127 111 156 101 106  60  16\n",
        "  71  32  31  49  59  37  63 140  84  30  26  40 155  95  13 132  21  78\n",
        "  47 135  62  79 112 162  53 110 133 153  29  76 152  51 151  85  75 121\n",
        "  96 130 125   1  38   5 150  23 138  15 141  97  66 143 109 146 126  43\n",
        " 134 157 114 136  34  19  70  57 137] \n",
        "test [ 11 103   8 144  74 149  93  80 139  61  64  73 147   4  98  14  92 120\n",
        "  94  25  17 161  81  24 113  86  27  44  35   3 159  56 107 115  83  52\n",
        "  58   7  41 128 145]\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "VI. Fit Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-55-2273118f7586>, line 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-2273118f7586>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model = svc.fit(X.ix[train_index], .ix[train_index])\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "VII. Test Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def score_model(actual, predicted):\n",
      "    score_df = pd.DataFrame([actual, predicted], index=['actual', 'predicted']).T\n",
      "    return {\"correct\":sum(score_df.actual == score_df.predicted), \"incorrect\":sum(score_df.actual != score_df.predicted)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df[['length','word_count']]\n",
      "y = df.outcome\n",
      "\n",
      "svc = LinearSVC()\n",
      "\n",
      "for train_index, test_index in rs:\n",
      "    model = svc.fit(X.ix[train_index], y.ix[train_index]) \n",
      "    actual = y.ix[test_index].values\n",
      "    predicted = model.predict(X.ix[test_index])\n",
      "    print score_model(actual, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'incorrect': 22, 'correct': 19}\n",
        "{'incorrect': 24, 'correct': 17}\n",
        "{'incorrect': 22, 'correct': 19}\n",
        "{'incorrect': 22, 'correct': 19}\n",
        "{'incorrect': 25, 'correct': 16}\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df[['length','word_count', 'header_in_outcome', 'outcome_in_header']]\n",
      "y = df.outcome\n",
      "\n",
      "svc = LinearSVC()\n",
      "model = svc.fit(X.ix[train_index], y.ix[train_index]) \n",
      "\n",
      "for train_index, test_index in rs:\n",
      "    model = svc.fit(X.ix[train_index], y.ix[train_index]) \n",
      "    actual = y.ix[test_index].values\n",
      "    predicted = model.predict(X.ix[test_index])\n",
      "    print score_model(actual, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'incorrect': 17, 'correct': 24}\n",
        "{'incorrect': 17, 'correct': 24}\n",
        "{'incorrect': 14, 'correct': 27}\n",
        "{'incorrect': 11, 'correct': 30}\n",
        "{'incorrect': 21, 'correct': 20}\n"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df[['length','word_count', 'header_in_outcome', 'outcome_in_header'] + term_features]\n",
      "y = df.outcome\n",
      "\n",
      "svc = LinearSVC()\n",
      "model = svc.fit(X.ix[train_index], y.ix[train_index]) \n",
      "modelb = svc.fit()\n",
      "\n",
      "for train_index, test_index in rs:\n",
      "    model = svc.fit(X.ix[train_index], y.ix[train_index]) \n",
      "    actual = y.ix[test_index].values\n",
      "    predicted = model.predict(X.ix[test_index])\n",
      "    print score_model(actual, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'incorrect': 20, 'correct': 21}\n",
        "{'incorrect': 19, 'correct': 22}\n",
        "{'incorrect': 14, 'correct': 27}\n",
        "{'incorrect': 13, 'correct': 28}\n",
        "{'incorrect': 22, 'correct': 19}\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}